{"nbformat_minor": 1, "cells": [{"source": "# Smart Water Quality Monitoring System - Deployment\n    \n1. [Classification Model Deployment](#Classification-Model-Deployment)\n    -  [1.1 Dataset Preparation](#DataSet-Preparation)\n    -  [1.2 Prepare Model](#Prepare-Model)\n    -  [1.3 Deploy Model](#Deploy-Model)\n    -  [1.4 Test Model](#Test-Model)\n    \n2. [Anomaly Detection Model Deployment](#AnomalyDetection-Model-Deployment)\n    -  [2.1 Dataset Preparation](#DataSet-Preparation2)\n    -  [2.2 Prepare Model](#Prepare-Model2)\n    -  [2.3 Deploy Model](#Deploy-Model2)\n    -  [2.4 Test Model](#Test-Model2)", "cell_type": "markdown", "metadata": {}}, {"source": "## 1. Classification Model Deployment <a class=\"anchor\" id=\"Classification-Model-Deployment\"><\/a>", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": 6, "cell_type": "code", "source": "#Suppress warning messages\n\nimport sys\nimport time\nimport warnings\nfrom IPython.display import Markdown, display\n\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")", "outputs": [], "metadata": {}}, {"execution_count": 7, "cell_type": "code", "source": "from sklearn.ensemble import RandomForestClassifier\nfrom azureml import Workspace\nfrom azureml import services\nfrom sklearn.cross_validation import train_test_split\nfrom azure.storage.blob import BlockBlobService\nimport pandas as pd\nimport numpy as np", "outputs": [], "metadata": {}}, {"source": "### 1.1. Dataset Preparation <a class=\"anchor\" id=\"DataSet-Preparation\"><\/a>", "cell_type": "markdown", "metadata": {}}, {"execution_count": 11, "cell_type": "code", "source": "#LOCALFILE is the file path    \nSTORAGEACCOUNTNAME= \"smartwaterstorage\"\nSTORAGEACCOUNTKEY= \"5GGqEdDGjlqyKRjnLIFogG1LzeUlyQ3iwMBFyDgR7pdB4VPMtuUwvBNUyAss98wrNTWa8KNTe+L7DxMcEWyY5Q==\"\nLOCALFILENAME= \"SW\"    \nCONTAINERNAME= \"smart-water-db\"\nblob_service=BlockBlobService (account_name=STORAGEACCOUNTNAME,account_key=STORAGEACCOUNTKEY)\n\nBLOBNAME= \"ModelTraining/Dataset/SW_TrainingData.csv\"\nblob_service.get_blob_to_path(CONTAINERNAME,BLOBNAME,LOCALFILENAME)   \n\n# Read Blob storage data\ndf_all = pd.read_csv(LOCALFILENAME, header=0) \n    \n# Standardize the labels generated by the models\narray = df_all.values\nX = array[:,4:9]\nY = array[:,9]\nY = Y.astype('int')\n\nvalidation_size = 0.20\nseed = 7\nX_train, X_validation, Y_train, Y_validation = train_test_split (X, Y, test_size=validation_size, random_state=seed)", "outputs": [], "metadata": {}}, {"source": "### 1.2. Prepare Model <a class=\"anchor\" id=\"Prepare-Model\"><\/a>", "cell_type": "markdown", "metadata": {}}, {"execution_count": 12, "cell_type": "code", "source": "model = RandomForestClassifier(min_samples_split = 2, \n                               bootstrap = True, \n                               min_samples_leaf = 1, \n                               n_estimators = 100, \n                               max_features = 4, \n                               max_depth = 10)\nmodel.fit(X_train, Y_train)", "outputs": [{"execution_count": 12, "output_type": "execute_result", "data": {"text/plain": "RandomForestClassifier(bootstrap=True, compute_importances=None,\n            criterion='gini', max_depth=10, max_features=4,\n            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n            min_samples_split=2, n_estimators=100, n_jobs=1,\n            oob_score=False, random_state=None, verbose=0)"}, "metadata": {}}], "metadata": {}}, {"source": "### 1.3. Deploy Model <a class=\"anchor\" id=\"Deploy-Model\"><\/a>", "cell_type": "markdown", "metadata": {}}, {"execution_count": 13, "cell_type": "code", "source": "# extract workspace info\nws = Workspace(\"9240b66313e840449c47cb8b1ed98a93\", \"9uPJO9gPZAM3LE2Z074MRqg+zTIgKdYf7qLgtXote45GCpg/e2AWdPnFbTLlGTpDMKsjHa3A7Svz0/jH2ILxig==\")\nworkdspace_id = ws.workspace_id\nauthorization_token = ws.authorization_token\n\n# set up web service\nfrom azureml import services\n@services.publish(workdspace_id, authorization_token)\n@services.types(WT=float, PH=float, DO=float, ORP=float, COND=float)\n@services.returns(int)\ndef SmartWater_MultiClassPredictor_2(WT, PH, DO, ORP, COND):\n    # predict the label\n    feature_vector = [WT, PH, DO, ORP, COND]\n    return model.predict(feature_vector)\n\n# save information about the web service\nservice_url = SmartWater_MultiClassPredictor_2.service.url \napi_key = SmartWater_MultiClassPredictor_2.service.api_key\nhelp_url = SmartWater_MultiClassPredictor_2.service.help_url\nservice_id = SmartWater_MultiClassPredictor_2.service.service_id", "outputs": [], "metadata": {}}, {"source": "### 1.4. Test Model <a class=\"anchor\" id=\"Test-Model\"><\/a>", "cell_type": "markdown", "metadata": {}}, {"execution_count": 15, "cell_type": "code", "source": "print(SmartWater_MultiClassPredictor_2(24.21,6.15,67.3,-0.057,517.2))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[3]\n"}], "metadata": {}}, {"source": "## 2. Anomaly Detection Model Deployment <a class=\"anchor\" id=\"AnomalyDetection-Model-Deployment\"><\/a>", "cell_type": "markdown", "metadata": {}}, {"execution_count": 9, "cell_type": "code", "source": "from sklearn import svm", "outputs": [], "metadata": {}}, {"source": "### 2.1. Dataset Preparation <a class=\"anchor\" id=\"DataSet-Preparation2\"><\/a>", "cell_type": "markdown", "metadata": {}}, {"execution_count": 10, "cell_type": "code", "source": "#LOCALFILE is the file path    \nSTORAGEACCOUNTNAME= \"smartwaterstorage\"\nSTORAGEACCOUNTKEY= \"5GGqEdDGjlqyKRjnLIFogG1LzeUlyQ3iwMBFyDgR7pdB4VPMtuUwvBNUyAss98wrNTWa8KNTe+L7DxMcEWyY5Q==\"\nLOCALFILENAME= \"SW\"    \nCONTAINERNAME= \"smart-water-db\"\nblob_service=BlockBlobService (account_name=STORAGEACCOUNTNAME,account_key=STORAGEACCOUNTKEY)\n    \nBLOBNAME= \"ModelTraining/Dataset/Accelerometer_Test.csv\"\nblob_service.get_blob_to_path(CONTAINERNAME,BLOBNAME,LOCALFILENAME)   \n\n# Read Blob storage data\ndf_Accelerometer = pd.read_csv(LOCALFILENAME, header=0) ", "outputs": [], "metadata": {}}, {"source": "### 2.2. Prepare Model <a class=\"anchor\" id=\"Prepare-Model2\"><\/a>", "cell_type": "markdown", "metadata": {}}, {"execution_count": 11, "cell_type": "code", "source": "X_train = df_Accelerometer[['ACC_X', 'ACC_Y', 'ACC_Z']].values\n\nACC_X = df_Accelerometer[\"ACC_X\"].values\nACC_Y = df_Accelerometer[\"ACC_Y\"].values\nACC_Z = df_Accelerometer[\"ACC_Z\"].values\nt =[x for x in range(len(ACC_X))]\n\nmodel = svm.OneClassSVM(nu=0.0084, kernel=\"rbf\", gamma=0.0001)\n\nmodel.fit(X_train)", "outputs": [{"execution_count": 11, "output_type": "execute_result", "data": {"text/plain": "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.0001, kernel='rbf',\n      max_iter=-1, nu=0.0084, random_state=None, shrinking=True, tol=0.001,\n      verbose=False)"}, "metadata": {}}], "metadata": {}}, {"source": "### 2.3. Deploy Model <a class=\"anchor\" id=\"Deploy-Model2\"><\/a>", "cell_type": "markdown", "metadata": {}}, {"execution_count": 12, "cell_type": "code", "source": "# extract workspace info\nws = Workspace(\"9240b66313e840449c47cb8b1ed98a93\", \"9uPJO9gPZAM3LE2Z074MRqg+zTIgKdYf7qLgtXote45GCpg/e2AWdPnFbTLlGTpDMKsjHa3A7Svz0/jH2ILxig==\")\nworkdspace_id = ws.workspace_id\nauthorization_token = ws.authorization_token\n\n# set up web service\nfrom azureml import services\n@services.publish(workdspace_id, authorization_token)\n@services.types(ACC_X=int, ACC_Y=int, ACC_Z=int)\n@services.returns(int)\ndef SmartWater_AnomalyDetector_2(ACC_X, ACC_Y, ACC_Z):\n    # predict the label\n    feature_vector = [ACC_X, ACC_Y, ACC_Z]\n    return model.predict(feature_vector)\n\n# save information about the web service\nservice_url = SmartWater_AnomalyDetector_2.service.url \napi_key = SmartWater_AnomalyDetector_2.service.api_key\nhelp_url = SmartWater_AnomalyDetector_2.service.help_url\nservice_id = SmartWater_AnomalyDetector_2.service.service_id", "outputs": [], "metadata": {}}, {"source": "### 2.4. Test Model <a class=\"anchor\" id=\"Test-Model2\"><\/a>", "cell_type": "markdown", "metadata": {}}, {"execution_count": 15, "cell_type": "code", "source": "print(SmartWater_AnomalyDetector_2(-6,100,1026))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[-1.]\n"}], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.13", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}